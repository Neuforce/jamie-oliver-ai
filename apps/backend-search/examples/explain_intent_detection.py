#!/usr/bin/env python3
"""
Â¿CÃ³mo el sistema "entiende" la INTENCIÃ“N del usuario?

ExplicaciÃ³n tÃ©cnica de cÃ³mo los embeddings capturan intenciÃ³n sin medir explÃ­citamente.
"""

from fastembed import TextEmbedding
import numpy as np

print("="*80)
print("Â¿CÃ“MO SE CAPTURA LA INTENCIÃ“N DEL USUARIO?")
print("="*80)

# ============================================================================
# PARTE 1: El modelo de embeddings fue ENTRENADO con millones de ejemplos
# ============================================================================
print("\n" + "="*80)
print("PARTE 1: Entrenamiento del Modelo de Embeddings")
print("="*80)

print("""
El modelo BAAI/bge-small-en-v1.5 fue entrenado con:

ğŸ“š Millones de pares de texto como:
   â€¢ Pregunta: "I need something quick" â†’ Respuesta: "Fast pasta recipe"
   â€¢ Pregunta: "comfort food for winter" â†’ Respuesta: "Hearty beef stew"
   â€¢ Pregunta: "healthy breakfast" â†’ Respuesta: "Light oatmeal with fruits"

ğŸ§  El modelo aprende PATRONES semÃ¡nticos:
   â€¢ "quick", "fast", "now", "hurry" â†’ URGENCIA/VELOCIDAD
   â€¢ "comfort", "cozy", "warm" â†’ RECONFORTANTE
   â€¢ "healthy", "light", "nutritious" â†’ SALUDABLE
   â€¢ "impress", "guests", "special" â†’ ELABORADO/FORMAL

ğŸ’¡ Estos patrones se codifican en los 384 nÃºmeros del embedding.
   NO es magia, es APRENDIZAJE de millones de ejemplos.
""")

# ============================================================================
# PARTE 2: Los embeddings capturan CONTEXTO, no solo palabras
# ============================================================================
print("\n" + "="*80)
print("PARTE 2: Embeddings = Contexto SemÃ¡ntico Codificado")
print("="*80)

model = TextEmbedding(model_name="BAAI/bge-small-en-v1.5")

# Ejemplos con diferentes "intenciones"
queries_con_intencion = {
    "urgencia": [
        "I'm hungry NOW",
        "need something quick",
        "fast recipe please",
    ],
    "confort": [
        "comfort food for a cold day",
        "something warm and cozy",
        "hearty meal",
    ],
    "salud": [
        "healthy dinner option",
        "light meal",
        "nutritious recipe",
    ],
    "impresionar": [
        "impress my dinner guests",
        "fancy recipe for special occasion",
        "elegant dish",
    ],
}

print("\nğŸ“Š Embeddings para queries con diferentes INTENCIONES:\n")

# Generar embeddings
embeddings_por_intencion = {}
for intencion, queries in queries_con_intencion.items():
    print(f"ğŸ¯ IntenciÃ³n: {intencion.upper()}")
    embeddings = []
    for q in queries:
        emb = list(model.embed([q]))[0]
        embeddings.append(emb)
        print(f"   '{q}'")
        print(f"   â†’ [{emb[0]:.3f}, {emb[1]:.3f}, {emb[2]:.3f}, ..., {emb[-1]:.3f}]")
    embeddings_por_intencion[intencion] = embeddings
    print()

# ============================================================================
# PARTE 3: Similitud DENTRO de cada intenciÃ³n vs ENTRE intenciones
# ============================================================================
print("\n" + "="*80)
print("PARTE 3: Similitud INTRA-intenciÃ³n vs INTER-intenciÃ³n")
print("="*80)

def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

print("\nğŸ“ Similitud DENTRO de la misma intenciÃ³n (ALTA):\n")

for intencion, embeddings in embeddings_por_intencion.items():
    sims = []
    for i, emb1 in enumerate(embeddings):
        for emb2 in embeddings[i+1:]:
            sim = cosine_similarity(emb1, emb2)
            sims.append(sim)
    
    avg_sim = np.mean(sims) if sims else 0
    print(f"   {intencion.upper()}: promedio {avg_sim:.3f}")
    print(f"   ğŸ’¡ Queries con la MISMA intenciÃ³n tienen vectores SIMILARES")

print("\nğŸ“ Similitud ENTRE diferentes intenciones (BAJA):\n")

intenciones = list(embeddings_por_intencion.keys())
for i, int1 in enumerate(intenciones):
    for int2 in intenciones[i+1:]:
        # Comparar primer embedding de cada intenciÃ³n
        sim = cosine_similarity(
            embeddings_por_intencion[int1][0],
            embeddings_por_intencion[int2][0]
        )
        print(f"   {int1} â†” {int2}: {sim:.3f}")

print(f"\nğŸ’¡ Queries con DIFERENTES intenciones tienen vectores MÃS DISTANTES")

# ============================================================================
# PARTE 4: Â¿CÃ³mo se "mide" la intenciÃ³n? NO se mide, se INFIERE
# ============================================================================
print("\n" + "="*80)
print("PARTE 4: La IntenciÃ³n NO se Mide, se INFIERE del Espacio Vectorial")
print("="*80)

print("""
ğŸ” Proceso paso a paso:

1ï¸âƒ£ Usuario escribe: "I'm hungry NOW"
   â†“
2ï¸âƒ£ Se genera embedding: [-0.109, 0.034, 0.021, ..., 0.015]
   â†“
3ï¸âƒ£ Este embedding estÃ¡ CERCA de:
   â€¢ "quick pasta" (sim: 0.82)
   â€¢ "fast meal" (sim: 0.79)
   â€¢ "easy recipe" (sim: 0.76)
   â†“
4ï¸âƒ£ Y LEJOS de:
   â€¢ "elaborate dish" (sim: 0.23)
   â€¢ "slow-cooked" (sim: 0.18)
   â†“
5ï¸âƒ£ Las recetas tambiÃ©n tienen embeddings:
   â€¢ "TOMATO & MUSSEL PASTA" tiene chunks como:
     - "Quick 20-minute meal" (alto en urgencia)
     - "Simple ingredients" (alto en simplicidad)
   â†“
6ï¸âƒ£ CÃ¡lculo de similitud coseno:
   query_emb <=> recipe_chunk_emb = 0.703
   â†“
7ï¸âƒ£ Â¡Match! La receta tiene chunks "cerca" del query en el espacio vectorial

ğŸ’¡ NO hay un "medidor de intenciÃ³n" explÃ­cito.
   La intenciÃ³n emerge de las DISTANCIAS en el espacio de 384 dimensiones.
""")

# ============================================================================
# PARTE 5: VisualizaciÃ³n conceptual del espacio vectorial
# ============================================================================
print("\n" + "="*80)
print("PARTE 5: VisualizaciÃ³n Conceptual del Espacio de 384D")
print("="*80)

print("""
Imagina el espacio vectorial como un mapa 3D (en realidad es 384D):

        ğŸ”ï¸ "elaborate dishes"
              â†‘
              |
              |
    ğŸ¥— "healthy"  ------>  âš¡ "quick/fast"
              |
              |
              â†“
        ğŸ² "comfort food"

Cuando el usuario dice:
  â€¢ "I'm hungry NOW" â†’ el embedding cae cerca de âš¡
  â€¢ "comfort food" â†’ el embedding cae cerca de ğŸ²
  â€¢ "healthy meal" â†’ el embedding cae cerca de ğŸ¥—
  â€¢ "impress guests" â†’ el embedding cae cerca de ğŸ”ï¸

Las recetas TAMBIÃ‰N tienen embeddings en este espacio:
  â€¢ "Quick pasta" â†’ cerca de âš¡
  â€¢ "Fish pie" â†’ cerca de ğŸ²
  â€¢ "Salad" â†’ cerca de ğŸ¥—

La bÃºsqueda encuentra recetas CERCANAS al query en este espacio.
""")

# ============================================================================
# PARTE 6: Â¿Por quÃ© funciona? Entrenamiento masivo
# ============================================================================
print("\n" + "="*80)
print("PARTE 6: Â¿Por QuÃ© Funciona Tan Bien?")
print("="*80)

print("""
âœ… El modelo BAAI/bge-small-en-v1.5 fue entrenado con:

ğŸ“š Datasets masivos:
   â€¢ MS MARCO (8.8M queries â†’ documents)
   â€¢ Natural Questions (307K questions â†’ passages)
   â€¢ BEIR (mÃºltiples dominios)
   â€¢ Millones de pares pregunta-respuesta

ğŸ¯ Tarea de entrenamiento:
   â€¢ Dado un query, predecir quÃ© documentos son RELEVANTES
   â€¢ El modelo aprende que:
     - "quick" â†’ documentos con "fast", "easy", "simple"
     - "comfort" â†’ documentos con "warm", "hearty", "cozy"
     - "healthy" â†’ documentos con "light", "nutritious", "fresh"

ğŸ§  Resultado:
   â€¢ 384 dimensiones que codifican SIGNIFICADO, no palabras
   â€¢ Cada dimensiÃ³n captura un "aspecto" semÃ¡ntico
   â€¢ Ejemplo (hipotÃ©tico):
     - Dim 23: "urgencia/velocidad" â†’ alta si query es urgente
     - Dim 157: "reconfortante" â†’ alta si query es sobre comfort
     - Dim 301: "saludable" â†’ alta si query es sobre health

ğŸ’¡ NO es un "medidor de intenciÃ³n" diseÃ±ado manualmente.
   Es un MODELO APRENDIDO de millones de ejemplos reales.
""")

# ============================================================================
# PARTE 7: Ejemplo prÃ¡ctico con nÃºmeros reales
# ============================================================================
print("\n" + "="*80)
print("PARTE 7: Ejemplo con NÃºmeros Reales")
print("="*80)

# Generar embeddings para comparaciÃ³n
query1 = "I'm hungry NOW"
query2 = "elaborate dinner for guests"

emb1 = list(model.embed([query1]))[0]
emb2 = list(model.embed([query2]))[0]

print(f"\nğŸ” Query 1: '{query1}'")
print(f"   Primeras 10 dimensiones: {emb1[:10]}")
print(f"   (384 dimensiones en total)")

print(f"\nğŸ” Query 2: '{query2}'")
print(f"   Primeras 10 dimensiones: {emb2[:10]}")
print(f"   (384 dimensiones en total)")

sim = cosine_similarity(emb1, emb2)
print(f"\nğŸ“ Similitud entre ambos: {sim:.3f}")
print(f"   ğŸ’¡ Baja similitud = diferentes intenciones")

# Ahora con recetas
recipe_quick = "Quick 20-minute tomato pasta"
recipe_elaborate = "Slow-cooked beef wellington with truffle sauce"

emb_quick = list(model.embed([recipe_quick]))[0]
emb_elaborate = list(model.embed([recipe_elaborate]))[0]

sim_q1_quick = cosine_similarity(emb1, emb_quick)
sim_q1_elaborate = cosine_similarity(emb1, emb_elaborate)
sim_q2_quick = cosine_similarity(emb2, emb_quick)
sim_q2_elaborate = cosine_similarity(emb2, emb_elaborate)

print(f"\nğŸ Receta 1: '{recipe_quick}'")
print(f"   Similitud con '{query1}': {sim_q1_quick:.3f} âœ… ALTA")
print(f"   Similitud con '{query2}': {sim_q2_quick:.3f} âŒ BAJA")

print(f"\nğŸ¥© Receta 2: '{recipe_elaborate}'")
print(f"   Similitud con '{query1}': {sim_q1_elaborate:.3f} âŒ BAJA")
print(f"   Similitud con '{query2}': {sim_q2_elaborate:.3f} âœ… ALTA")

print(f"\nğŸ’¡ El sistema AUTOMÃTICAMENTE matchea intenciones sin medirlas explÃ­citamente!")

# ============================================================================
# RESUMEN FINAL
# ============================================================================
print("\n" + "="*80)
print("ğŸ“ RESUMEN: Â¿CÃ³mo se Captura la IntenciÃ³n?")
print("="*80)

print("""
âŒ NO hay un "medidor de intenciÃ³n" explÃ­cito
âœ… La intenciÃ³n emerge de:

1ï¸âƒ£ ENTRENAMIENTO MASIVO
   â€¢ Modelo aprende de millones de ejemplos
   â€¢ Patrones semÃ¡nticos se codifican en 384 dimensiones

2ï¸âƒ£ ESPACIO VECTORIAL
   â€¢ Queries similares â†’ vectores cercanos
   â€¢ Queries diferentes â†’ vectores lejanos

3ï¸âƒ£ DISTANCIA COSENO
   â€¢ Mide cercanÃ­a en el espacio de 384D
   â€¢ CercanÃ­a = intenciÃ³n similar

4ï¸âƒ£ NO usa palabras clave
   â€¢ "I'm hungry NOW" no busca "hungry" literalmente
   â€¢ Busca vectores CERCANOS que capturen urgencia/rapidez

ğŸ¯ En otras palabras:
   â€¢ NO medimos intenciÃ³n directamente
   â€¢ La intenciÃ³n estÃ¡ CODIFICADA en los embeddings
   â€¢ La bÃºsqueda encuentra recetas con embeddings SIMILARES
   â€¢ Similitud de embeddings = similitud de intenciÃ³n

ğŸš€ Por eso funciona mejor que bÃºsqueda por keywords:
   â€¢ Keywords: "hungry" â†’ busca literal "hungry"
   â€¢ Embeddings: "hungry" â†’ busca concepto de "comida rÃ¡pida/urgencia"
""")

print("="*80)
print("âœ… ExplicaciÃ³n completada!")
print("="*80)

